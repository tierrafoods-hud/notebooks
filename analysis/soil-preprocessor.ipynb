{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def silt_and_clay_columns(df):\n",
    "    # Handle silt and clay columns if present\n",
    "    if {'silt', 'clay'}.issubset(df.columns):\n",
    "        df['silt_plus_clay'] = df[['silt', 'clay']].sum(axis=1, skipna=True)\n",
    "        df.drop(columns=['silt', 'clay'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def om_and_bd_columns(df):\n",
    "    # Calculate organic matter metrics if orgc present\n",
    "    if 'orgc' in df.columns:\n",
    "        # Use vectorized operations for better performance\n",
    "        organic_matter = 1.724 * df['orgc']\n",
    "        df = df.assign(\n",
    "            organic_matter=organic_matter,\n",
    "            bulk_density=1.62 - 0.06 * organic_matter\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_dataset(df):\n",
    "    # drop columns with 70% or more missing values\n",
    "    df = df.dropna(thresh=0.3 * len(df), axis=1)\n",
    "    # remove outliers using z-score\n",
    "    # df = df[(df.select_dtypes(include=[np.number]).apply(lambda x: x.abs() < 3).all(axis=1))]\n",
    "    # remove negative values // cannot do this as we have negative values in the data for bulk density\n",
    "    # df = df[df.select_dtypes(include=[np.number]).ge(0).all(axis=1)]\n",
    "    # replace invalid dates\n",
    "    # df['date'] = df.apply(lambda row: replace_invalid_dates(row['date']), axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the raw soil dataset\n",
    "df = pd.read_csv(\"../../outputs/Mexico_wosis_merged.csv\")\n",
    "# add silt and clay columns\n",
    "df = silt_and_clay_columns(df)\n",
    "# add organic matter and bulk density columns\n",
    "df = om_and_bd_columns(df)\n",
    "\n",
    "# save the cleaned dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group obervations by latitude and longitude to check for duplicates\n",
    "duplicates = df.groupby(['latitude', 'longitude']).size().reset_index(name='count').copy()\n",
    "# show only duplicates\n",
    "\n",
    "sorted_duplicates = duplicates[duplicates['count'] > 1].sort_values(by='count', ascending=False)\n",
    "sorted_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "grouped_data = df.groupby(['latitude', 'longitude']).size().reset_index(name='count')\n",
    "\n",
    "map_h = folium.Map(\n",
    "    location=[grouped_data['latitude'].mean(), grouped_data['longitude'].mean()],\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    zoom_start=4,\n",
    "    min_zoom=4,\n",
    "    max_zoom=6\n",
    ")\n",
    "\n",
    "gradient = {0.2: 'blue', 0.4: 'green', 0.6: 'yellow', 0.8: 'red'}\n",
    "HeatMap(grouped_data,\n",
    "        name=\"Soil Observations\",\n",
    "        radius=9, \n",
    "        blur=8,\n",
    "        min_opacity=0.2,\n",
    "        ).add_to(map_h)\n",
    "\n",
    "map_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of upper and lower depths\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a 2D histogram (heatmap) of upper vs lower depths\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist2d(df['upper_depth'], df['lower_depth'], bins=50, cmap='viridis')\n",
    "plt.colorbar(label='Count')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Heatmap of Upper vs Lower Depths')\n",
    "plt.xlabel('Upper Depth (cm)')\n",
    "plt.ylabel('Lower Depth (cm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "# Convert date column to datetime and handle invalid dates\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "# create quarters\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Get distribution of years\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['date'].dt.year.hist(bins=30)\n",
    "plt.title('Distribution of Soil Measurements by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spatial distribution of the data for the selected year\n",
    "# Load Mexico shapefile\n",
    "mexico = gpd.read_file(\"D:/tierra/data/natural_earth/ne_110m_admin_0_countries.shp\")\n",
    "mexico = mexico[mexico['ADMIN'] == 'Mexico']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a specific year (e.g. 2000)\n",
    "YEAR = 2004\n",
    "df_year = df[df['year'] == YEAR]\n",
    "\n",
    "print(f\"Number of measurements in year {YEAR}: {len(df_year)}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for quarter in range(1, 5):\n",
    "    ax = axes[quarter-1]\n",
    "    # Get data for this quarter\n",
    "    quarter_data = df_year[df_year['quarter'] == quarter]\n",
    "    \n",
    "    # Plot Mexico boundaries\n",
    "    mexico.plot(ax=ax, color='lightgrey', edgecolor='black')\n",
    "    # Plot points\n",
    "    ax.scatter(quarter_data['longitude'], quarter_data['latitude'], \n",
    "              c=quarter_data['date'], cmap='viridis', alpha=0.6)\n",
    "    ax.set_title(f'Soil Measurements in Q{quarter} 2000 (n={len(quarter_data)})')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.suptitle(f'Spatial Distribution of Soil Measurements in {YEAR} by Quarter')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
